{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40168fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a65840",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[2, 3],[7, 9],])\n",
    "B = torch.tensor([[10, 1],[8, 6],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135435ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 44,  20],\n",
      "        [142,  61]])\n",
      "tensor([[ 44,  20],\n",
      "        [142,  61]])\n"
     ]
    }
   ],
   "source": [
    "matmul1 = torch.matmul(A ,B) # Para multiplicação matricial é necessário que os tensores tenham shapes iguais e de tamanho igual\n",
    "matmul2 = A @ B\n",
    "print(matmul1)\n",
    "print(matmul2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64893e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71411d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Original: torch.Size([2, 3])\n",
      "Shape transpose: torch.Size([3, 2])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "transpose = matrix.T\n",
    "print(f\"Shape Original: {matrix.shape}\")\n",
    "print(f\"Shape transpose: {transpose.shape}\")\n",
    "print(transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c5fd7",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "Usando o reshape é possível remoldar o tensor, adquirindo o formato desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89625e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix = torch.rand(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9402fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4498, 0.3873, 0.5997, 0.8850],\n",
       "        [0.2736, 0.5594, 0.7668, 0.0768],\n",
       "        [0.4608, 0.9131, 0.6125, 0.6927]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_matrix.reshape(3, 4) # Note que ao fazer reshape, os valores devem ser multiplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef05bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4498, 0.3873, 0.5997, 0.8850, 0.2736, 0.5594],\n",
       "        [0.7668, 0.0768, 0.4608, 0.9131, 0.6125, 0.6927]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_matrix.reshape(2, 6) # 2 * 6 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab62d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = new_matrix.reshape(2, 3, 2) # 2 * 2 * 3 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2428c",
   "metadata": {},
   "source": [
    "## Flatten (achatar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d732f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4498, 0.3873, 0.5997, 0.8850, 0.2736, 0.5594, 0.7668, 0.0768, 0.4608,\n",
       "        0.9131, 0.6125, 0.6927])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted.flatten() # Transforma um tensor em um tensor de linha única"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848df1a",
   "metadata": {},
   "source": [
    "### Flatten a partir de dimensão específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a51f8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(10, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d8b1741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcea1637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_1 = tensor.flatten(start_dim=1)\n",
    "flat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cbaa984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_2 = tensor.flatten(start_dim=2)\n",
    "flat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "681b33bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_in = torch.randn(1, 3, 1, 4)\n",
    "squeezed_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "squeezed = squeezed_in.squeeze() # O método squeeze serve para comprimir tensores\n",
    "print(squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e5c8dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed = squeezed.unsqueeze(2)\n",
    "unsqueezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95786c",
   "metadata": {},
   "source": [
    "## Any e All\n",
    "Any e All são operadores voltados para conectivos universais e exclusórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a409ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3., 51., 95.],\n",
       "        [87., 98., 33.],\n",
       "        [82., 41., 93.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 3).mul_(100).ceil_()\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6f27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_greater = torch.any(tensor > 10) # Retorna True, pois existe ao menos um valor maior do que 10\n",
    "any_greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942755b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lower = torch.all(tensor < 10) # Retorna False, pois nem todos os valores são menores do que 10\n",
    "all_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493aa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2787e+15)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = tensor.prod() # Faz o produto de todos os valores\n",
    "prod"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
